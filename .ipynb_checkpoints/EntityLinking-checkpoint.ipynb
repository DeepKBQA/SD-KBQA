{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/meti-94/OpenQA/blob/main/EntityLinking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NJdWHETOja9V",
    "outputId": "8928394b-ac18-484c-de68-e4600792455d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 3.1 MB 5.1 MB/s \n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 43.2 MB/s \n",
      "\u001b[K     |████████████████████████████████| 56 kB 4.5 MB/s \n",
      "\u001b[K     |████████████████████████████████| 895 kB 46.6 MB/s \n",
      "\u001b[K     |████████████████████████████████| 596 kB 50.4 MB/s \n",
      "\u001b[K     |████████████████████████████████| 50 kB 2.9 MB/s \n",
      "\u001b[?25h  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers -q\n",
    "!pip install fuzzywuzzy -q\n",
    "!pip install python-Levenshtein -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K7diqBfqRKwI",
    "outputId": "88a40f05-eb11-4527-8423-ece4f24c3554"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3021, in _dep_map\n",
      "    return self.__dep_map\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2815, in __getattr__\n",
      "    raise AttributeError(attr)\n",
      "AttributeError: _DistInfoDistribution__dep_map\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 180, in _main\n",
      "    status = self.run(options, args)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/req_command.py\", line 199, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/commands/install.py\", line 385, in run\n",
      "    conflicts = self._determine_conflicts(to_install)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/commands/install.py\", line 515, in _determine_conflicts\n",
      "    return check_install_conflicts(to_install)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/operations/check.py\", line 103, in check_install_conflicts\n",
      "    package_set, _ = create_package_set_from_installed()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/operations/check.py\", line 45, in create_package_set_from_installed\n",
      "    package_set[name] = PackageDetails(dist.version, dist.requires())\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2736, in requires\n",
      "    dm = self._dep_map\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3023, in _dep_map\n",
      "    self.__dep_map = self._compute_dependencies()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3033, in _compute_dependencies\n",
      "    reqs.extend(parse_requirements(req))\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3094, in parse_requirements\n",
      "    yield Requirement(line)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3101, in __init__\n",
      "    super(Requirement, self).__init__(requirement_string)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/packaging/requirements.py\", line 113, in __init__\n",
      "    req = REQUIREMENT.parseString(requirement_string)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 1943, in parseString\n",
      "    loc, tokens = self._parse(instring, 0)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n",
      "    loc, tokens = self.parseImpl(instring, preloc, doActions)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 4069, in parseImpl\n",
      "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n",
      "    loc, tokens = self.parseImpl(instring, preloc, doActions)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 4254, in parseImpl\n",
      "    ret = e._parse(instring, loc, doActions)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n",
      "    loc, tokens = self.parseImpl(instring, preloc, doActions)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 4069, in parseImpl\n",
      "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n",
      "    loc, tokens = self.parseImpl(instring, preloc, doActions)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 4849, in parseImpl\n",
      "    loc, tokens = self.expr._parse(instring, loc, doActions, callPreParse=False)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n",
      "    loc, tokens = self.parseImpl(instring, preloc, doActions)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 4069, in parseImpl\n",
      "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n",
      "    loc, tokens = self.parseImpl(instring, preloc, doActions)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 4069, in parseImpl\n",
      "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n",
      "    loc, tokens = self.parseImpl(instring, preloc, doActions)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 4462, in parseImpl\n",
      "    return self.expr._parse(instring, loc, doActions, callPreParse=False)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n",
      "    loc, tokens = self.parseImpl(instring, preloc, doActions)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 4052, in parseImpl\n",
      "    loc, resultlist = self.exprs[0]._parse(instring, loc, doActions, callPreParse=False)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n",
      "    loc, tokens = self.parseImpl(instring, preloc, doActions)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 4254, in parseImpl\n",
      "    ret = e._parse(instring, loc, doActions)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n",
      "    loc, tokens = self.parseImpl(instring, preloc, doActions)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 4462, in parseImpl\n",
      "    return self.expr._parse(instring, loc, doActions, callPreParse=False)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n",
      "    loc, tokens = self.parseImpl(instring, preloc, doActions)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 4069, in parseImpl\n",
      "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n",
      "    loc, tokens = self.parseImpl(instring, preloc, doActions)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 4254, in parseImpl\n",
      "    ret = e._parse(instring, loc, doActions)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n",
      "    loc, tokens = self.parseImpl(instring, preloc, doActions)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 4254, in parseImpl\n",
      "    ret = e._parse(instring, loc, doActions)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 1687, in _parseNoCache\n",
      "    loc, tokens = self.parseImpl(instring, preloc, doActions)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 2893, in parseImpl\n",
      "    raise ParseException(instring, loc, self.errmsg, self)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/main.py\", line 71, in main\n",
      "    return command.main(cmd_args)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 104, in main\n",
      "    return self._main(args)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 212, in _main\n",
      "    logger.critical(\"Operation cancelled by user\")\n",
      "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1425, in critical\n",
      "    self._log(CRITICAL, msg, args, **kwargs)\n",
      "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1514, in _log\n",
      "    self.handle(record)\n",
      "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1524, in handle\n",
      "    self.callHandlers(record)\n",
      "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1586, in callHandlers\n",
      "    hdlr.handle(record)\n",
      "  File \"/usr/lib/python3.7/logging/__init__.py\", line 894, in handle\n",
      "    self.emit(record)\n",
      "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1025, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/utils/logging.py\", line 208, in format\n",
      "    msg = super().format(record)\n",
      "  File \"/usr/lib/python3.7/logging/__init__.py\", line 869, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/utils/logging.py\", line 124, in format\n",
      "    def format(self, record):\n",
      "KeyboardInterrupt\n",
      "Cloning into 'BuboQA'...\n",
      "remote: Enumerating objects: 1383, done.\u001b[K\n",
      "remote: Total 1383 (delta 0), reused 0 (delta 0), pack-reused 1383\u001b[K\n",
      "Receiving objects: 100% (1383/1383), 361.07 KiB | 18.05 MiB/s, done.\n",
      "Resolving deltas: 100% (908/908), done.\n",
      "/content/BuboQA\n",
      "Running fetch_dataset script\n",
      "mkdir: cannot create directory ‘data’: File exists\n",
      "Downloading SimpleQuestions dataset...\n",
      "\n",
      "--2021-10-29 15:13:24--  https://git.uwaterloo.ca/jimmylin/BuboQA-data/raw/master/SimpleQuestions_v2.tgz\n",
      "Resolving git.uwaterloo.ca (git.uwaterloo.ca)... 129.97.83.4\n",
      "Connecting to git.uwaterloo.ca (git.uwaterloo.ca)|129.97.83.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 423435590 (404M) [application/x-gzip]\n",
      "Saving to: ‘SimpleQuestions_v2.tgz’\n",
      "\n",
      "SimpleQuestions_v2. 100%[===================>] 403.82M  61.9MB/s    in 5.8s    \n",
      "\n",
      "2021-10-29 15:13:34 (69.3 MB/s) - ‘SimpleQuestions_v2.tgz’ saved [423435590/423435590]\n",
      "\n",
      "\n",
      "\n",
      "Unzipping SimpleQuestions dataset...\n",
      "\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
      "./._SimpleQuestions_v2\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
      "SimpleQuestions_v2/\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
      "SimpleQuestions_v2/._annotated_fb_data_test.txt\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
      "SimpleQuestions_v2/annotated_fb_data_test.txt\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
      "SimpleQuestions_v2/._annotated_fb_data_train.txt\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
      "SimpleQuestions_v2/annotated_fb_data_train.txt\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
      "SimpleQuestions_v2/._annotated_fb_data_valid.txt\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
      "SimpleQuestions_v2/annotated_fb_data_valid.txt\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
      "SimpleQuestions_v2/freebase-subsets/\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
      "SimpleQuestions_v2/._LICENSE.txt\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
      "SimpleQuestions_v2/LICENSE.txt\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
      "SimpleQuestions_v2/README.txt\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
      "SimpleQuestions_v2/freebase-subsets/freebase-FB2M.txt\n"
     ]
    }
   ],
   "source": [
    "!pip install fuzzywuzzy -q\n",
    "!git clone https://github.com/castorini/BuboQA.git\n",
    "%cd /content/BuboQA\n",
    "!bash setup.sh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S0f7RqUdZp26"
   },
   "outputs": [],
   "source": [
    "cp -r /content/BuboQA/indexes /content/drive/MyDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t9vfTp60jaCc"
   },
   "outputs": [],
   "source": [
    "cp -r /content/BuboQA/data/processed_simplequestions_dataset /content/drive/MyDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1wdQ6F9_8gZK"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "u1FODKh38oiT"
   },
   "outputs": [],
   "source": [
    "# mapping between MIDs and names in the form of dict['MID']=['str1', 'str2', ...,  'strN']\n",
    "with open('/content/drive/MyDrive/indexes/names_2M.pkl', 'rb') as f:\n",
    "    mid2name = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "uKJ6BgWcmYVm"
   },
   "outputs": [],
   "source": [
    "# In/Out degree for each MID in the form of dict['MID']=[In degree, Out degree]\n",
    "with open('/content/drive/MyDrive/indexes/degrees_2M.pkl', 'rb') as f:\n",
    "    degrees_2M = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "WEsQueYYm7a3"
   },
   "outputs": [],
   "source": [
    "# reverse mapping between string and MID in the form of dict['string']=[('MID', 'actual string', 'freebase type') ...] \n",
    "with open('/content/drive/MyDrive/indexes/entity_2M.pkl', 'rb') as f:\n",
    "    entity_2M = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "T38YnAzrrnfn"
   },
   "outputs": [],
   "source": [
    "# mapping between MIDs and Relations in the form of dict['MID']=[{'fb:common.topic.notable_types', 'fb:people.person.gender', 'fb:people.person.profession'}]\n",
    "with open('/content/drive/MyDrive/indexes/reachability_2M.pkl', 'rb') as f:\n",
    "    reachability_2M = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "CBvgJHEt7oDk"
   },
   "outputs": [],
   "source": [
    "reverb2freebace = pd.read_csv('/content/drive/MyDrive/reverb2freebase.csv')\n",
    "reverb2freebace['freebase_ID_argument1'] = reverb2freebace['freebase_ID_argument1'].apply(lambda string:'fb:m.'+string)\n",
    "reverb2freebace['conf'] = reverb2freebace['conf'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iPVj0Hmbvtql",
    "outputId": "ae8d0dc2-12ac-4aae-dd54-74ee98b54879"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153354/153354 [00:18<00:00, 8441.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original MIDs: 1951909\tMatched MIDs: 144572\n",
      "Original Entity Strings: 2995306\tAdded Entity Strings: 144491\n",
      "Original Relations Count: 7188598\tAdded Relations Count: 144572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mid_count = len(mid2name)\n",
    "string_count = sum([len(name) for name in mid2name.values()])\n",
    "original_relations = sum([len(relation) for relation in reachability_2M.values()])\n",
    "\n",
    "matched_mids = 0\n",
    "new_entity_strings = 0\n",
    "new_relations = 0\n",
    "\n",
    "for index, row in tqdm(reverb2freebace.iterrows(), total=reverb2freebace.shape[0]):\n",
    "  mid = row['freebase_ID_argument1']\n",
    "  reverb_string = row['arg1']\n",
    "  relation = row['rel']\n",
    "  conf = str(row['conf'])\n",
    "  try:\n",
    "    temp = mid2name[mid]\n",
    "    matched_mids+=1\n",
    "  except:\n",
    "    continue\n",
    "  if reverb_string not in temp:\n",
    "    temp.append((reverb_string, conf))\n",
    "    new_entity_strings+=1\n",
    "  temp = reachability_2M[mid]\n",
    "  if relation not in temp:\n",
    "    temp.add((relation, conf))\n",
    "    new_relations+=1\n",
    "  try:\n",
    "    temp = entity_2M[reverb_string]\n",
    "    temp.add((mid, reverb_string, conf))\n",
    "  except:\n",
    "    entity_2M[reverb_string] = set([(mid, reverb_string, conf)])\n",
    "  \n",
    "  degrees_2M[mid][1]+=1\n",
    "\n",
    "\n",
    "print(f'\\nOriginal MIDs: {mid_count}\\tMatched MIDs: {matched_mids}')\n",
    "print(f'Original Entity Strings: {string_count}\\tAdded Entity Strings: {new_entity_strings}') \n",
    "print(f'Original Relations Count: {original_relations}\\tAdded Relations Count: {new_relations}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "lYRchs2PClTv"
   },
   "outputs": [],
   "source": [
    "def get_ngram(text):\n",
    "    #ngram = set()\n",
    "    ngram = []\n",
    "    tokens = str(text).split()\n",
    "    for i in range(len(tokens)+1):\n",
    "        for j in range(i):\n",
    "            if i-j <= 3:\n",
    "                #ngram.add(\" \".join(tokens[j:i]))\n",
    "                temp = \" \".join(tokens[j:i])\n",
    "                if temp not in ngram:\n",
    "                    ngram.append(temp)\n",
    "    #ngram = list(ngram)\n",
    "    ngram = sorted(ngram, key=lambda x: len(x.split()), reverse=True)\n",
    "    return ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "tnDsLrfrwaPg"
   },
   "outputs": [],
   "source": [
    "def get_stat_inverted_index(reverse_index):\n",
    "    \"\"\"\n",
    "    Get the number of entry and max length of the entry (How many mid in an entry)\n",
    "    \"\"\"\n",
    "    with open(filename, \"rb\") as handler:\n",
    "        global  inverted_index\n",
    "        inverted_index = pickle.load(handler)\n",
    "        inverted_index = defaultdict(str, inverted_index)\n",
    "    print(\"Total type of text: {}\".format(len(inverted_index)))\n",
    "    max_len = 0\n",
    "    _entry = \"\"\n",
    "    for entry, value in inverted_index.items():\n",
    "        if len(value) > max_len:\n",
    "            max_len = len(value)\n",
    "            _entry = entry\n",
    "    print(\"Max Length of entry is {}, text is {}\".format(max_len, _entry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "APzP-OYtwejL",
    "outputId": "6153fbc1-403d-4532-c69d-86ab32202e61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total type of text: 4881352\n",
      "Max Length of entry is 249717, text is [('fb:m.0f2slw', 'linnton , oregon', 'fb:common.topic.alias'), ('fb:m.048sdrr', 'suburban heights , florida', 'fb:common.topic.alias'), ('fb:m.04c47cj', 'east franklin , vermont', 'fb:common.topic.alias'), ('fb:m.0vnwt', 'birch run township , michigan', 'fb:common.topic.alias'), ('fb:m.01p6v_n', 'mcguire sisters , the', 'fb:common.topic.alias'), ('fb:m.0343wn', 'henry iii jules de bourbon , prince de conde', 'fb:common.topic.alias'), ('fb:m.0z49t66', 'fidelio , op 72 : no. 11 - introduction / gott ! welch ! dunkel hier !', 'fb:type.object.name'), ('fb:m.01mcf1l', 'complete recorded works in chronological order , volume 10 : 26 january to 17 december 1940', 'fb:type.object.name'), ('fb:m.0j244p1', 'koudizé , issiaka', 'fb:common.topic.alias'), ('fb:m.0cmfy0y', 'if you have a mountain of snow , keep it in the shade', 'fb:common.topic.alias'), ('fb:m.03c1n3_', 'abel , steve', 'fb:common.topic.alias'), ('fb:m.01sq0qs', 'taylor , kasey', 'fb:common.topic.alias'), ('fb:m.048ww2b', 'summit hill , georgia', 'fb:common.topic.alias'), ('fb:m.03npcr4', 'roffey , yonne', 'fb:type.object.name'), ('fb:m.03cpd9y', 'stump pond , pembroke', 'fb:common.topic.alias'), ('fb:m.02q5pq4', 'warren , dale', 'fb:common.topic.alias'), ('fb:m.075lx1', \"charles-victor prévot , vicomte d'arlincourt\", 'fb:type.object.name'), ('fb:m.03f3pm5', 'burgess , tim', 'fb:common.topic.alias'), ('fb:m.0497fnb', 'quaise , nantucket', 'fb:common.topic.alias'), ('fb:m.0dyxrr_', 'concerto pour violon et orchestre et ré mineur , op. 47 : iii. allegro ma non tanto', 'fb:type.object.name'), ('fb:m.0bwgqd', 'someone comes to town , someone leaves town', 'fb:type.object.name'), ('fb:m.04bm4hn', 'jacksonville , pennsylvania', 'fb:common.topic.alias'), ('fb:m.03hhb7', 'alkborough , england', 'fb:common.topic.alias'), ('fb:m.02cys_', 'city of boroondara , melbourne', 'fb:common.topic.alias'), ('fb:m.0cpdrw5', 'university of social welfare and rehabilitation sciences , main campus', 'fb:common.topic.alias'), ('fb:m.0489lht', 'toyon , california', 'fb:type.object.name'), ('fb:m.0b69ppk', 'first love , last rites', 'fb:type.object.name'), ('fb:m.048rl7t', 'houston , delaware', 'fb:common.topic.alias'), ('fb:m.06w2l3g', 'kyiv mohyla business school , main campus', 'fb:common.topic.alias'), ('fb:m.0484vt5', 'mayfair , alabama', 'fb:common.topic.alias'), ('fb:m.07tbqj', 'nationalmuseum , stockholm', 'fb:common.topic.alias'), ('fb:m.0520t90', 'lasca , alabama', 'fb:common.topic.alias'), ('fb:m.02rcdwy', 'ordacsehi , hungary', 'fb:common.topic.alias'), ('fb:m.048qckj', 'kirkgaard acres , colorado', 'fb:common.topic.alias'), ('fb:m.0cpbwp5', 'st. petersburg state pharmaceutical college , main campus', 'fb:common.topic.alias'), ('fb:m.048ptjt', 'waltonia , colorado', 'fb:common.topic.alias'), ('fb:m.0gvs3lc', 'embassy of myanmar in washington , d.c .', 'fb:type.object.name'), ('fb:m.02z3c_r', 'greatest hits , volume 1 - the singles', 'fb:common.topic.alias'), ('fb:m.01d2f3', 'weyburn , canada', 'fb:common.topic.alias'), ('fb:m.04hdm16', 'crustaceans , crab , alaska king , raw', 'fb:common.topic.alias'), ('fb:m.04bclnh', 'mountain view , new york', 'fb:common.topic.alias'), ('fb:m.0bt7fk', 'oakwell stadium , barnsley', 'fb:common.topic.alias'), ('fb:m.048xcgb', 'eagle court , georgia', 'fb:common.topic.alias'), ('fb:m.0_yvrr', \"rhapsody on a theme of paganini , op. 43 : variation ii ( l'istesso tempo )\", 'fb:common.topic.alias'), ('fb:m.0c4n38', 'minnear , kerry', 'fb:common.topic.alias'), ('fb:m.0487fqv', 'wolford addition , arkansas', 'fb:common.topic.alias'), ('fb:m.0g8sgb', 'borgo ticino , france', 'fb:common.topic.alias'), ('fb:m.04bb7pb', 'buckhorn , nevada', 'fb:type.object.name'), ('fb:m.01mhqg4', 'killer barbies , the', 'fb:common.topic.alias'), ('fb:m.03h5dkv', 'primera iglesia baptista , casa grande', 'fb:common.topic.alias'), ('fb:m.0_71m', 'lower merion township , pennsylvania', 'fb:common.topic.alias'), ('fb:m.01h7d90', \"the bootleg series , volume 4 : live 1966 : the `` royal albert hall '' concert ( disc 2 )\", 'fb:common.topic.alias'), ('fb:m.01lvl5', 'dickinson , bruce', 'fb:common.topic.alias'), ('fb:m.04895jh', 'cummings , california', 'fb:common.topic.alias'), ('fb:m.0310hdr', 'locked on , volume 2', 'fb:type.object.name'), ('fb:m.080lq_2', 'twelvemile corner , illinois', 'fb:type.object.name'), ('fb:m.0qpydfm', 'inverso , tres y media vueltas en posición c', 'fb:common.topic.alias'), ('fb:m.0clvkgx', 'cet-san diego , main campus', 'fb:common.topic.alias'), ('fb:m.04925cd', 'scarlet , indiana', 'fb:common.topic.alias'), ('fb:m.04b2qc2', 'davis , mississippi', 'fb:common.topic.alias'), ('fb:m.0dvrq2', 'gumeracha , south australia', 'fb:common.topic.alias'), ('fb:m.0g8s3p', 'ameno , france', 'fb:common.topic.alias'), ('fb:m.08yf6k', 'samuel stevens , jr .', 'fb:type.object.name'), ('fb:m.03_18vb', 'techno club , volume 14', 'fb:type.object.name'), ('fb:m.0xd3m', 'highland grove township , minnesota', 'fb:common.topic.alias'), ('fb:m.03skyg', 'beslan , russia', 'fb:common.topic.alias'), ('fb:m.0gr0lx', 'nughedu santa vittoria , italy', 'fb:common.topic.alias'), ('fb:m.0j3d03v', 'balsamus , the man of satan', 'fb:common.topic.alias'), ('fb:m.054s5w6', 'rapids water park , riviera beach', 'fb:common.topic.alias'), ('fb:m.037lqlt', 'technoclub : classix , volume 1', 'fb:type.object.name'), ('fb:m.0f9_23', 'semmes , alabama', 'fb:common.topic.alias'), ('fb:m.0n_6kzz', 'farewell , my dear sorrows', 'fb:common.topic.alias'), ('fb:m.048stdg', 'nowatney , florida', 'fb:type.object.name'), ('fb:m.010gyk', 'west mountain , utah', 'fb:common.topic.alias'), ('fb:m.0fqr2rv', 'kvitnes , henning', 'fb:common.topic.alias'), ('fb:m.01h41kd', 'the best of columbia records radio hour , volume 2', 'fb:type.object.name'), ('fb:m.03q736g', 'mount resplendent , jasper national park , canada', 'fb:type.object.name'), ('fb:m.0488_j0', 'clyde , california', 'fb:common.topic.alias'), ('fb:m.0dqdch7', \"symphony no.4 in c minor , d.417 `` tragic '' : ii. andante\", 'fb:type.object.name'), ('fb:m.0clvx09', 'bellingham beauty school , main campus', 'fb:common.topic.alias'), ('fb:m.0qpn9', 'mesa patios , arizona', 'fb:common.topic.alias'), ('fb:m.04c2q32', 'johnson corner , virginia', 'fb:common.topic.alias'), ('fb:m.042jt6', 'sintaluta , saskatchewan', 'fb:common.topic.alias'), ('fb:m.06zsg75', 'jin , sha', 'fb:common.topic.alias'), ('fb:m.02rs0p5', 'alfonso d. tagle , sr .', 'fb:common.topic.alias'), ('fb:m.048y6vf', 'high acres mobile home park , iowa', 'fb:common.topic.alias'), ('fb:m.0gjcqr', 'piario , italy', 'fb:common.topic.alias'), ('fb:m.0ch2xxb', 'portal , arizona', 'fb:common.topic.alias'), ('fb:m.02r088h', 'blamed , the', 'fb:common.topic.alias'), ('fb:m.0fsfjcx', 'have violin , will swing', 'fb:type.object.name'), ('fb:m.04y5gm', 'time , the', 'fb:common.topic.alias'), ('fb:m.06_mj5', 'maverick baseball stadium , adelanto', 'fb:common.topic.alias'), ('fb:m.0762x1', 'aliwal north , south africa', 'fb:common.topic.alias'), ('fb:m.0zpzg', 'jim thorpe , pennsylvania', 'fb:common.topic.alias'), ('fb:m.02bbyw', 'university of pisa , main campus', 'fb:common.topic.alias'), ('fb:m.01rvnly', 'lee , jeanne', 'fb:common.topic.alias'), ('fb:m.04ct10f', 'kyorin university , mitaka', 'fb:common.topic.alias'), ('fb:m.0489g_f', 'reward , inyo county , california', 'fb:type.object.name'), ('fb:m.09v2pwc', 'true colors : the best of sonic the hedgehog , part 2', 'fb:common.topic.alias'), ('fb:m.0gvjy1y', 'public school no. 99 , main campus', 'fb:type.object.name')]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "inverted_index = defaultdict(str, entity_2M)\n",
    "print(\"Total type of text: {}\".format(len(inverted_index)))\n",
    "max_len = 0\n",
    "_entry = \"\"\n",
    "for entry, value in inverted_index.items():\n",
    "  if len(value) > max_len:\n",
    "    max_len = len(value)\n",
    "    _entry = list(value)\n",
    "print(\"Max Length of entry is {}, text is {}\".format(max_len, _entry[:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "5B9pOgtEpyM9"
   },
   "outputs": [],
   "source": [
    "del entity_2M\n",
    "del degrees_2M\n",
    "del reachability_2M\n",
    "del mid2name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "id": "hE1tWP2xub7t",
    "outputId": "6cb9a87a-a544-4a3a-8b62-61944d67804f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ExID</th>\n",
       "      <th>arg1</th>\n",
       "      <th>rel</th>\n",
       "      <th>arg2</th>\n",
       "      <th>narg1</th>\n",
       "      <th>nrel</th>\n",
       "      <th>narg2</th>\n",
       "      <th>csents</th>\n",
       "      <th>conf</th>\n",
       "      <th>urls</th>\n",
       "      <th>argument1</th>\n",
       "      <th>relation_phrase</th>\n",
       "      <th>argument2</th>\n",
       "      <th>freebase_ID_argument1</th>\n",
       "      <th>freebase_entity_name</th>\n",
       "      <th>link_score</th>\n",
       "      <th>link_ambiguity_score</th>\n",
       "      <th>idk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13505</td>\n",
       "      <td>0</td>\n",
       "      <td>is not equal to</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>be not equal to</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.92645</td>\n",
       "      <td>http://open-encyclopedia.com/Invalid_proof|htt...</td>\n",
       "      <td>0</td>\n",
       "      <td>is not equal to</td>\n",
       "      <td>1</td>\n",
       "      <td>fb:m.089n7</td>\n",
       "      <td>0 (number)</td>\n",
       "      <td>12.0642</td>\n",
       "      <td>0.093666</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13970</td>\n",
       "      <td>0</td>\n",
       "      <td>is reserved for</td>\n",
       "      <td>the Operating System</td>\n",
       "      <td>0</td>\n",
       "      <td>be reserve for</td>\n",
       "      <td>the operating system</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96718</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Scheduling_priority</td>\n",
       "      <td>0</td>\n",
       "      <td>is reserved for</td>\n",
       "      <td>the Operating System</td>\n",
       "      <td>fb:m.089n7</td>\n",
       "      <td>0 (number)</td>\n",
       "      <td>10.8344</td>\n",
       "      <td>0.391962</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>14012</td>\n",
       "      <td>0</td>\n",
       "      <td>are automatically</td>\n",
       "      <td>zero</td>\n",
       "      <td>0</td>\n",
       "      <td>be automatically</td>\n",
       "      <td>zero</td>\n",
       "      <td>1</td>\n",
       "      <td>0.93811</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Kodaira-Nakano_va...</td>\n",
       "      <td>0</td>\n",
       "      <td>are automatically</td>\n",
       "      <td>zero</td>\n",
       "      <td>fb:m.089n7</td>\n",
       "      <td>0 (number)</td>\n",
       "      <td>17.3057</td>\n",
       "      <td>0.332805</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>14144</td>\n",
       "      <td>0</td>\n",
       "      <td>is exactly</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>be exactly</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.94094</td>\n",
       "      <td>http://www.includipedia.com/wiki/E_%28mathemat...</td>\n",
       "      <td>0</td>\n",
       "      <td>is exactly</td>\n",
       "      <td>1</td>\n",
       "      <td>fb:m.089n7</td>\n",
       "      <td>0 (number)</td>\n",
       "      <td>15.8416</td>\n",
       "      <td>0.438347</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>14177</td>\n",
       "      <td>0</td>\n",
       "      <td>pertenece</td>\n",
       "      <td>a S.</td>\n",
       "      <td>0</td>\n",
       "      <td>pertenece</td>\n",
       "      <td>a s.</td>\n",
       "      <td>1</td>\n",
       "      <td>0.91043</td>\n",
       "      <td>http://en.wikipedia.org/wiki/es:N%C3%BAmero</td>\n",
       "      <td>0</td>\n",
       "      <td>pertenece</td>\n",
       "      <td>a S.</td>\n",
       "      <td>fb:m.0669fq</td>\n",
       "      <td>January 0</td>\n",
       "      <td>14.1981</td>\n",
       "      <td>0.554785</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   ExID arg1  ... link_score link_ambiguity_score idk\n",
       "0           0  13505    0  ...    12.0642             0.093666 NaN\n",
       "1           1  13970    0  ...    10.8344             0.391962 NaN\n",
       "2           2  14012    0  ...    17.3057             0.332805 NaN\n",
       "3           3  14144    0  ...    15.8416             0.438347 NaN\n",
       "4           4  14177    0  ...    14.1981             0.554785 NaN\n",
       "\n",
       "[5 rows x 19 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverb2freebace.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iZKYAo6uthuW",
    "outputId": "aa786d11-22ca-429f-e089-b791ac78caa3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153354"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverb2freebace.iloc[168]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XvZpm7hDDN0Z",
    "outputId": "2ee229d9-3712-44c2-bbd7-4b610ba4b2ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21619 5003\n",
      "26622\n"
     ]
    }
   ],
   "source": [
    "pred_df_freebase = pd.read_excel('/content/freebase_answers.xlsx')\n",
    "pred_df_reverb = pd.read_excel('/content/reverb_answers.xlsx')\n",
    "print(len(pred_df_freebase), len(pred_df_reverb))\n",
    "pred_df = pd.concat([pred_df_freebase, pred_df_reverb])\n",
    "print(len(pred_df))\n",
    "# pred_df['Question'] = pred_df['questions'].apply(lambda item:' '.join(eval(item)).replace(' #', ''))\n",
    "# gold_df_freebase = pd.read_excel('/content/drive/MyDrive/data_freebase/test_useful_records.xlsx')\n",
    "# gold_df_\n",
    "# print(len(pred_df), len(gold_df))\n",
    "# df = pred_df.merge(gold_df, on='Question', how ='inner')\n",
    "# print(len(df))\n",
    "\n",
    "# predicteds = df['node'].astype(str).to_list()\n",
    "# golds = df['Answer'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "th3H6blNzq3o",
    "outputId": "f19eaf66-133f-48df-a733-afa706e8c225"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import sys\n",
    "def entity_linking(data_type, predicteds, golds, HITS_TOP_ENTITIES, output):\n",
    "    stopword = set(stopwords.words('english'))\n",
    "    fout = open(output, 'w')\n",
    "    total = 0\n",
    "    top1 = 0\n",
    "    top3 = 0\n",
    "    top5 = 0\n",
    "    top10 = 0\n",
    "    top20 = 0\n",
    "    top50 = 0\n",
    "    top100 = 0\n",
    "\n",
    "    for idx, (predicted, gold_id) in tqdm(enumerate(zip(predicteds, golds))):\n",
    "        total += 1\n",
    "        C = []\n",
    "        C_scored = []\n",
    "        tokens = get_ngram(predicted)\n",
    "\n",
    "        if len(tokens) > 0:\n",
    "            maxlen = len(tokens[0].split())\n",
    "        for item in tokens:\n",
    "            if len(item.split()) < maxlen and len(C) == 0:\n",
    "                maxlen = len(item.split())\n",
    "            if len(item.split()) < maxlen and len(C) > 0:\n",
    "                break\n",
    "            if item in stopword:\n",
    "                continue\n",
    "            C.extend(inverted_index[item])\n",
    "        for mid_text_type in set(C):\n",
    "            score = fuzz.ratio(mid_text_type[1], predicted.strip()) / 100.0\n",
    "            C_scored.append((mid_text_type, score))\n",
    "        C_scored.sort(key=lambda t: t[1], reverse=True)\n",
    "        cand_mids = C_scored[:HITS_TOP_ENTITIES]\n",
    "        for mid_text_type, score in cand_mids:\n",
    "            fout.write(\" %%%% {}\\t{}\\t{}\\t{}\".format(mid_text_type[0], mid_text_type[1], mid_text_type[2], score))\n",
    "        fout.write('\\n')\n",
    "        \n",
    "        midList = [x[0][0] for x in cand_mids]\n",
    "        if gold_id in midList[:1]:\n",
    "            top1 += 1\n",
    "        if gold_id in midList[:3]:\n",
    "            top3 += 1\n",
    "        if gold_id in midList[:5]:\n",
    "            top5 += 1\n",
    "        if gold_id in midList[:10]:\n",
    "            top10 += 1\n",
    "        if gold_id in midList[:20]:\n",
    "            top20 += 1\n",
    "        if gold_id in midList[:50]:\n",
    "            top50 += 1\n",
    "        if gold_id in midList[:100]:\n",
    "            top100 += 1\n",
    "\n",
    "    print(data_type)\n",
    "    print(\"Top1 Entity Linking Accuracy: {}\".format(top1 / total))\n",
    "    print(\"Top3 Entity Linking Accuracy: {}\".format(top3 / total))\n",
    "    print(\"Top5 Entity Linking Accuracy: {}\".format(top5 / total))\n",
    "    print(\"Top10 Entity Linking Accuracy: {}\".format(top10 / total))\n",
    "    print(\"Top20 Entity Linking Accuracy: {}\".format(top20 / total))\n",
    "    print(\"Top50 Entity Linking Accuracy: {}\".format(top50 / total))\n",
    "    print(\"Top100 Entity Linking Accuracy: {}\".format(top100 / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tq1PuwgjEePq",
    "outputId": "0de6c849-1db3-48b8-d10b-9e2a3eb535e9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22041it [00:54, 405.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "Top1 Entity Linking Accuracy: 0.6250170137471076\n",
      "Top3 Entity Linking Accuracy: 0.734903135066467\n",
      "Top5 Entity Linking Accuracy: 0.7700648790889706\n",
      "Top10 Entity Linking Accuracy: 0.8055895830497709\n",
      "Top20 Entity Linking Accuracy: 0.833401388321764\n",
      "Top50 Entity Linking Accuracy: 0.8661131527607641\n",
      "Top100 Entity Linking Accuracy: 0.8838981897373077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "entity_linking('test', predicteds, golds, 100, \"./results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bERerC2RF0n6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNhs0juKbbm60U1qrOtfCIF",
   "collapsed_sections": [],
   "include_colab_link": true,
   "mount_file_id": "1w2gni9UytivlnTVEI3C49F9StZ9e6Y2G",
   "name": "Freebase Reverb Unification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
