{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP.ipynb",
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPFrblZ9GdSS+kBgmmUXDCN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meti-94/OpenQA/blob/main/OpenQA_v2/src/Before%20Table%202.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'transformers[torch]' -q\n",
        "!pip install fuzzywuzzy -q\n",
        "!pip install python-Levenshtein -q\n",
        "!pip install pattern -q"
      ],
      "metadata": {
        "id": "1wb8Y-zFpE3d",
        "outputId": "3991d156-0e00-4e86-bd3d-6ead90425d52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m104.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.4/169.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.5/89.5 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.1/81.1 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.4/237.4 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m348.4/348.4 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pattern (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for mysqlclient (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QD_CQcqmoZ23",
        "outputId": "592a5ce5-b13f-4a6c-98a3-dfcd18e88345"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/meti-94/OpenQA.git\n",
        "%cd OpenQA/OpenQA_v2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vg2YG2BRnOh7",
        "outputId": "a9ca082b-de4f-4925-bc54-af9fa0caea43"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'OpenQA'...\n",
            "remote: Enumerating objects: 296, done.\u001b[K\n",
            "remote: Counting objects: 100% (59/59), done.\u001b[K\n",
            "remote: Compressing objects: 100% (47/47), done.\u001b[K\n",
            "remote: Total 296 (delta 28), reused 27 (delta 9), pack-reused 237\u001b[K\n",
            "Receiving objects: 100% (296/296), 102.64 MiB | 16.10 MiB/s, done.\n",
            "Resolving deltas: 100% (131/131), done.\n",
            "/content/OpenQA/OpenQA_v2/src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/OpenQA/OpenQA_v2\n",
        "!python src/train.py NodeEdgeDetector False 0"
      ],
      "metadata": {
        "id": "bYQidXZ2L-3w",
        "outputId": "99d13463-a417-4c93-9639-2bc81bc296c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/OpenQA/OpenQA_v2\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/config.json HTTP/1.1\" 200 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/config.json HTTP/1.1\" 200 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "INFO:root:Train Dataset Contains 9921 Samples.\n",
            "INFO:root:Valid Dataset Contains 1751 Samples.\n",
            "INFO:root:Test Dataset Contains 5003 Samples.\n",
            "Train Epoch Number 1: 100% 50/50 [00:25<00:00,  1.98it/s]\n",
            "INFO:root:Epoch number: 1 Train Loss is equal: 373.1737060546875\n",
            "Eval Epoch Number 1: 100% 9/9 [00:01<00:00,  7.06it/s]\n",
            "INFO:root:Epoch number: 1 Eval Loss is equal: 23.882957458496094\n",
            "Train Epoch Number 2: 100% 50/50 [00:25<00:00,  1.95it/s]\n",
            "INFO:root:Epoch number: 2 Train Loss is equal: 29.426986694335938\n",
            "Eval Epoch Number 2: 100% 9/9 [00:01<00:00,  6.56it/s]\n",
            "INFO:root:Epoch number: 2 Eval Loss is equal: 16.175567626953125\n",
            "Train Epoch Number 3: 100% 50/50 [00:26<00:00,  1.88it/s]\n",
            "INFO:root:Epoch number: 3 Train Loss is equal: 19.296363830566406\n",
            "Eval Epoch Number 3: 100% 9/9 [00:01<00:00,  6.65it/s]\n",
            "INFO:root:Epoch number: 3 Eval Loss is equal: 17.792753219604492\n",
            "Train Epoch Number 4: 100% 50/50 [00:25<00:00,  1.92it/s]\n",
            "INFO:root:Epoch number: 4 Train Loss is equal: 15.154541015625\n",
            "Eval Epoch Number 4: 100% 9/9 [00:01<00:00,  6.77it/s]\n",
            "INFO:root:Epoch number: 4 Eval Loss is equal: 13.330638885498047\n",
            "Train Epoch Number 5: 100% 50/50 [00:26<00:00,  1.91it/s]\n",
            "INFO:root:Epoch number: 5 Train Loss is equal: 12.373675346374512\n",
            "Eval Epoch Number 5: 100% 9/9 [00:01<00:00,  6.70it/s]\n",
            "INFO:root:Epoch number: 5 Eval Loss is equal: 15.183719635009766\n",
            "Train Epoch Number 6: 100% 50/50 [00:26<00:00,  1.90it/s]\n",
            "INFO:root:Epoch number: 6 Train Loss is equal: 11.159611701965332\n",
            "Eval Epoch Number 6: 100% 9/9 [00:01<00:00,  6.74it/s]\n",
            "INFO:root:Epoch number: 6 Eval Loss is equal: 16.076807022094727\n",
            "Predicting ...: 100% 51/51 [00:04<00:00, 12.48it/s]\n",
            "INFO:root:Dataset-wide F1, precision and recall:\n",
            "INFO:root:0.9885260370697264, 0.9902740937223696, 0.986784140969163\n",
            "INFO:root:Averaged F1, precision and recall:\n",
            "INFO:root:0.9920081279080869, 0.9919848091145312, 0.9920314477979878\n",
            "INFO:root:Span accuracy\n",
            "INFO:root:0.9852088746751949\n",
            "INFO:root:Dataset-wide F1, precision and recall:\n",
            "INFO:root:0.9929626052159515, 0.9929626052159515, 0.9929626052159515\n",
            "INFO:root:Averaged F1, precision and recall:\n",
            "INFO:root:0.995500935346531, 0.9953669068400229, 0.9956349999524103\n",
            "INFO:root:Span accuracy\n",
            "INFO:root:0.9768139116530082\n",
            "Question                    Node               Edge\n",
            "--------------------------  -----------------  --------------------\n",
            "Where was Bill Gates Born?  ['bill', 'gates']  ['was', 'born', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 src/sbs_output.py test"
      ],
      "metadata": {
        "id": "D6o6NkaMAD25",
        "outputId": "93b1e9de-720e-4309-a2f3-1fa921e077e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEBUG:jaxlib.mlir._mlir_libs:Initializing MLIR with module: _site_initialize_0\n",
            "DEBUG:jaxlib.mlir._mlir_libs:Registering dialects from initializer <module 'jaxlib.mlir._mlir_libs._site_initialize_0' from '/usr/local/lib/python3.10/dist-packages/jaxlib/mlir/_mlir_libs/_site_initialize_0.so'>\n",
            "DEBUG:jax._src.xla_bridge:No jax_plugins namespace packages available\n",
            "DEBUG:jax._src.path:etils.epath found. Using etils.epath for file I/O.\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/config.json HTTP/1.1\" 200 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/config.json HTTP/1.1\" 200 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Indexing ...: 100% 407236/407236 [00:24<00:00, 16832.43it/s]\n",
            "  0% 15/26622 [00:09<5:03:59,  1.46it/s]Exception ignored in: <generator object tqdm.__iter__ at 0x780c4c59d930>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tqdm/std.py\", line 1183, in __iter__\n",
            "    yield obj\n",
            "KeyboardInterrupt: \n",
            "  0% 15/26622 [00:10<5:01:13,  1.47it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/OpenQA/OpenQA_v2/src/sbs_output.py\", line 48, in <module>\n",
            "    temp = RKBG.query(node=node, edge=edge)\n",
            "  File \"/content/OpenQA/OpenQA_v2/src/graph.py\", line 184, in query\n",
            "    nodes = self.tfidf_nodes_query(node)\n",
            "  File \"/content/OpenQA/OpenQA_v2/src/graph.py\", line 163, in tfidf_nodes_query\n",
            "    ranks = {k:v for k,v in zip(self.nodes, similarities)}\n",
            "  File \"/content/OpenQA/OpenQA_v2/src/graph.py\", line 163, in <dictcomp>\n",
            "    ranks = {k:v for k,v in zip(self.nodes, similarities)}\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 src/sbs_output.py valid"
      ],
      "metadata": {
        "id": "5qkGT0EQ_rsZ",
        "outputId": "2e77bf1e-bded-4ce4-b58d-656a52de8c37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEBUG:jaxlib.mlir._mlir_libs:Initializing MLIR with module: _site_initialize_0\n",
            "DEBUG:jaxlib.mlir._mlir_libs:Registering dialects from initializer <module 'jaxlib.mlir._mlir_libs._site_initialize_0' from '/usr/local/lib/python3.10/dist-packages/jaxlib/mlir/_mlir_libs/_site_initialize_0.so'>\n",
            "DEBUG:jax._src.xla_bridge:No jax_plugins namespace packages available\n",
            "DEBUG:jax._src.path:etils.epath found. Using etils.epath for file I/O.\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/config.json HTTP/1.1\" 200 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/config.json HTTP/1.1\" 200 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Indexing ...: 100% 407236/407236 [00:24<00:00, 16295.43it/s]\n",
            "  2% 197/12560 [01:53<1:58:36,  1.74it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/OpenQA/OpenQA_v2/src/sbs_output.py\", line 48, in <module>\n",
            "    temp = RKBG.query(node=node, edge=edge)\n",
            "  File \"/content/OpenQA/OpenQA_v2/src/graph.py\", line 184, in query\n",
            "    nodes = self.tfidf_nodes_query(node)\n",
            "  File \"/content/OpenQA/OpenQA_v2/src/graph.py\", line 164, in tfidf_nodes_query\n",
            "    sorted_ranks = {k: v for k, v in sorted(ranks.items(), key=lambda item:item[1], reverse=True)[:min(len(ranks), cutoff)]}\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XFyjUgA2TH6w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}